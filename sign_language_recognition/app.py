"""
æ‰‹è¯­è¯†åˆ«Webåº”ç”¨
åŸºäºStreamlitæ„å»ºçš„Webç•Œé¢
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import time
from pathlib import Path
from hand_landmarks import HandLandmarkDetector
from gesture_classifier import GestureClassifier
import os

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ‰‹è¯­è¯†åˆ«ç³»ç»Ÿ",
    page_icon="âœ‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼ - ç°ä»£åŒ–UIè®¾è®¡
st.markdown("""
<style>
    /* å…¨å±€æ ·å¼ */
    :root {
        --primary-gradient: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        --secondary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        --success-color: #00bf63;
        --danger-color: #ff4757;
        --warning-color: #ffa502;
        --info-color: #0984e3;
        --light-bg: #f8f9fa;
        --dark-bg: #2d3436;
        --card-shadow: 0 8px 30px rgba(0, 0, 0, 0.12);
        --transition: all 0.3s ease;
    }
    
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-header {
        font-size: 3.5rem;
        font-weight: 800;
        text-align: center;
        margin: 1.5rem 0;
        background: var(--primary-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        position: relative;
        z-index: 1;
    }
    
    /* é¢„æµ‹æ¡†æ ·å¼ - ç°ä»£å¡ç‰‡è®¾è®¡ */
    .prediction-box {
        background: var(--secondary-gradient);
        border-radius: 16px;
        padding: 2rem;
        text-align: center;
        color: white;
        margin: 1.5rem 0;
        box-shadow: var(--card-shadow);
        transition: var(--transition);
    }
    
    .prediction-box:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 35px rgba(0, 0, 0, 0.15);
    }
    
    .prediction-text {
        font-size: 5rem;
        font-weight: 900;
        margin: 0.5rem 0;
        letter-spacing: -2px;
        text-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    }
    
    .confidence-text {
        font-size: 1.5rem;
        opacity: 0.9;
        margin-top: 0.5rem;
    }
    
    /* æŒ‰é’®æ ·å¼ - ç°ä»£åŒ–è®¾è®¡ */
    .stButton > button {
        width: 100%;
        background: var(--primary-gradient);
        color: white;
        font-size: 1.2rem;
        font-weight: bold;
        padding: 0.75rem 1.5rem;
        border: none;
        border-radius: 10px;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        transition: var(--transition);
        cursor: pointer;
        position: relative;
        overflow: hidden;
        z-index: 1;
    }
    
    .stButton > button::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.4), transparent);
        transition: var(--transition);
        z-index: -1;
    }
    
    .stButton > button:hover::before {
        left: 100%;
    }
    
    .stButton > button:hover {
        transform: translateY(-3px);
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
    }
    
    /* çŠ¶æ€æ¡†æ ·å¼ */
    .stInfo {
        background-color: #e3f2fd;
        border-left: 4px solid var(--info-color);
        border-radius: 8px;
        padding: 1rem;
    }
    
    .stError {
        background-color: #ffebee;
        border-left: 4px solid var(--danger-color);
        border-radius: 8px;
        padding: 1rem;
    }
    
    .stWarning {
        background-color: #fff3e0;
        border-left: 4px solid var(--warning-color);
        border-radius: 8px;
        padding: 1rem;
    }
    
    .stSuccess {
        background-color: #e8f5e9;
        border-left: 4px solid var(--success-color);
        border-radius: 8px;
        padding: 1rem;
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    [data-testid="stSidebar"] {
        background-color: var(--light-bg);
        border-right: 1px solid #e0e0e0;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    h1, h2, h3, h4, h5, h6 {
        font-weight: 700;
        color: var(--dark-bg);
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        box-shadow: var(--card-shadow);
        margin-bottom: 1.5rem;
        transition: var(--transition);
    }
    
    .card:hover {
        transform: translateY(-2px);
        box-shadow: 0 12px 40px rgba(0, 0, 0, 0.1);
    }
    
    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div {
        background: var(--primary-gradient);
        border-radius: 5px;
        height: 10px;
    }
    
    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .main-header {
            font-size: 2.5rem;
        }
        
        .prediction-text {
            font-size: 3rem;
        }
        
        .prediction-box {
            padding: 1.5rem;
        }
        
        .stButton > button {
            font-size: 1rem;
            padding: 0.6rem 1.2rem;
        }
    }
    
    /* æ»šåŠ¨æ¡æ ·å¼ */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 10px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: #c1c1c1;
        border-radius: 10px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #a8a8a8;
    }
    
    /* é¡µé¢åŠ è½½åŠ¨ç”» */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .stApp > header {
        animation: fadeIn 0.5s ease-out;
    }
    
    .stApp > main {
        animation: fadeIn 0.5s ease-out 0.1s both;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–Session State
if 'recognizer' not in st.session_state:
    st.session_state.recognizer = None
if 'detector' not in st.session_state:
    st.session_state.detector = None
if 'classifier' not in st.session_state:
    st.session_state.classifier = None
if 'prediction_history' not in st.session_state:
    st.session_state.prediction_history = []
if 'is_running' not in st.session_state:
    st.session_state.is_running = False
if 'cap' not in st.session_state:
    st.session_state.cap = None

def find_model_file():
    """æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶ï¼Œå°è¯•å¤šä¸ªå¯èƒ½çš„ä½ç½®"""
    possible_paths = [
        Path('gesture_model.pkl'),  # å½“å‰å·¥ä½œç›®å½•
        Path(__file__).parent / 'gesture_model.pkl',  # app.pyæ‰€åœ¨ç›®å½•
        Path.cwd() / 'gesture_model.pkl',  # å½“å‰å·¥ä½œç›®å½•ï¼ˆæ˜ç¡®ï¼‰
    ]
    
    for path in possible_paths:
        if path.exists():
            return str(path)
    
    return None

def initialize_components():
    """åˆå§‹åŒ–æ£€æµ‹å™¨å’Œåˆ†ç±»å™¨"""
    if st.session_state.detector is None:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ‰‹éƒ¨æ£€æµ‹å™¨..."):
            st.session_state.detector = HandLandmarkDetector()
    
    if st.session_state.classifier is None:
        with st.spinner("æ­£åœ¨åŠ è½½æ‰‹åŠ¿åˆ†ç±»æ¨¡å‹..."):
            # å°è¯•æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
            model_path = find_model_file()
            if model_path:
                st.session_state.classifier = GestureClassifier(model_path=model_path)
            else:
                st.session_state.classifier = GestureClassifier()
            
            if st.session_state.classifier.model is None:
                st.error("âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼")
                st.info("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿ `gesture_model.pkl` å·²ä¸Šä¼ åˆ°GitHubä»“åº“")
                # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯"):
                    st.write("å°è¯•æŸ¥æ‰¾çš„è·¯å¾„ï¼š")
                    for path in [Path('gesture_model.pkl'), Path(__file__).parent / 'gesture_model.pkl']:
                        exists = path.exists()
                        st.write(f"- `{path}`: {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
                    st.write(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
                    st.write(f"app.pyä½ç½®: {Path(__file__).parent}")
                return False
    return True

def smooth_prediction(prediction):
    """å¹³æ»‘é¢„æµ‹ç»“æœ"""
    st.session_state.prediction_history.append(prediction)
    if len(st.session_state.prediction_history) > 5:
        st.session_state.prediction_history.pop(0)
    
    if len(st.session_state.prediction_history) >= 3:
        from collections import Counter
        most_common = Counter(st.session_state.prediction_history).most_common(1)[0]
        return most_common[0], most_common[1] / len(st.session_state.prediction_history)
    
    return prediction, 0.5

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    # æ ‡é¢˜
    st.markdown('<h1 class="main-header">âœ‹ æ‰‹è¯­è¯†åˆ«ç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        
        # æ¨¡å‹çŠ¶æ€æ£€æŸ¥
        model_path = find_model_file()
        if model_path:
            st.success(f"âœ… æ¨¡å‹å·²æ‰¾åˆ°: {model_path}")
        else:
            st.error("âŒ æ¨¡å‹æœªæ‰¾åˆ°")
            st.info("è¯·ç¡®ä¿ `gesture_model.pkl` å·²ä¸Šä¼ åˆ°GitHubä»“åº“")
            with st.expander("ğŸ” æŸ¥çœ‹è°ƒè¯•ä¿¡æ¯"):
                st.write("å°è¯•æŸ¥æ‰¾çš„è·¯å¾„ï¼š")
                for path in [Path('gesture_model.pkl'), Path(__file__).parent / 'gesture_model.pkl']:
                    exists = path.exists()
                    st.write(f"- `{path}`: {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
                st.write(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
                st.write(f"app.pyä½ç½®: {Path(__file__).parent}")
        
        st.markdown("---")
        
        # åŠŸèƒ½é€‰æ‹©
        st.subheader("ğŸ“‹ åŠŸèƒ½")
        page = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["å®æ—¶è¯†åˆ«", "æ•°æ®æ”¶é›†", "æ¨¡å‹è®­ç»ƒ", "ä½¿ç”¨è¯´æ˜"],
            index=0
        )
        
        st.markdown("---")
        st.subheader("â„¹ï¸ å…³äº")
        st.info("""
        **æ‰‹è¯­è¯†åˆ«ç³»ç»Ÿ v1.0**
        
        æ”¯æŒ30ä¸ªæ‰‹è¯­å­—æ¯è¯†åˆ«ï¼š
        - A-Z (26ä¸ªå­—æ¯)
        - ZH, CH, SH, NG
        
        åŸºäºMediaPipeå’Œæœºå™¨å­¦ä¹ 
        """)
    
    # ä¸»å†…å®¹åŒºåŸŸ
    if page == "å®æ—¶è¯†åˆ«":
        show_recognition_page()
    elif page == "æ•°æ®æ”¶é›†":
        show_data_collection_page()
    elif page == "æ¨¡å‹è®­ç»ƒ":
        show_training_page()
    elif page == "ä½¿ç”¨è¯´æ˜":
        show_instructions_page()

def show_recognition_page():
    """æ˜¾ç¤ºå®æ—¶è¯†åˆ«é¡µé¢"""
    st.header("ğŸ¥ å®æ—¶æ‰‹è¯­è¯†åˆ«")
    
    # æ·»åŠ ä½¿ç”¨æç¤º
    st.info("""
    ğŸ’¡ **ä½¿ç”¨æç¤º**ï¼š
    1. ç‚¹å‡»"å¼€å§‹è¯†åˆ«"æŒ‰é’®å¯åŠ¨å®æ—¶æ‘„åƒå¤´
    2. å°†æ‰‹æ”¾åœ¨æ‘„åƒå¤´å‰ï¼Œåšå‡ºæ‰‹è¯­å­—æ¯æ‰‹åŠ¿
    3. ç³»ç»Ÿä¼šå®æ—¶è¯†åˆ«å¹¶æ˜¾ç¤ºç»“æœ
    4. æ”¯æŒè¯†åˆ«30ä¸ªæ‰‹è¯­å­—æ¯ï¼ˆA-Z, ZH, CH, SH, NGï¼‰
    5. ç‚¹å‡»"åœæ­¢è¯†åˆ«"å¯å…³é—­æ‘„åƒå¤´
    """)
    
    if not initialize_components():
        return
    
    # åˆå§‹åŒ–Session State
    if 'running' not in st.session_state:
        st.session_state.running = False
    if 'camera' not in st.session_state:
        st.session_state.camera = None
    if 'detection_history' not in st.session_state:
        st.session_state.detection_history = []
    
    # åˆ›å»ºå¸ƒå±€
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“¹ å®æ—¶æ‘„åƒå¤´ç”»é¢")
        # åˆ›å»ºå¼€å§‹/åœæ­¢æŒ‰é’®
        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            if st.button("ğŸš€ å¼€å§‹è¯†åˆ«", key="start_button"):
                st.session_state.running = True
        with col_btn2:
            if st.button("ğŸ›‘ åœæ­¢è¯†åˆ«", key="stop_button"):
                st.session_state.running = False
                if st.session_state.camera is not None:
                    st.session_state.camera.release()
                    st.session_state.camera = None
        
        # åˆ›å»ºå›¾åƒå ä½ç¬¦
        image_placeholder = st.empty()
        
        # å®æ—¶è§†é¢‘å¤„ç†
        if st.session_state.running:
            try:
                # æ‰“å¼€æ‘„åƒå¤´
                    if st.session_state.camera is None:
                        # æ˜¾ç¤ºè¯¦ç»†åˆå§‹åŒ–çŠ¶æ€
                        image_placeholder.info("æ­£åœ¨å°è¯•æ‰“å¼€æ‘„åƒå¤´...è¯·ç¡®ä¿å·²æˆäºˆåº”ç”¨æ‘„åƒå¤´è®¿é—®æƒé™")
                        print("å¼€å§‹åˆå§‹åŒ–æ‘„åƒå¤´...")
                        
                        # æ ¹æ®æµ‹è¯•ç»“æœï¼Œåªå°è¯•ç´¢å¼•0ï¼Œå¹¶ä½¿ç”¨AVFOUNDATIONåç«¯
                        camera_idx = 0
                        backend = cv2.CAP_AVFOUNDATION  # ä¼˜å…ˆä½¿ç”¨AVFoundationåç«¯
                        camera_opened = False
                        
                        try:
                            print(f"å°è¯•ä½¿ç”¨åç«¯ {backend} æ‰“å¼€æ‘„åƒå¤´ç´¢å¼• {camera_idx}")
                            
                            # åˆ›å»ºVideoCaptureå¯¹è±¡
                            st.session_state.camera = cv2.VideoCapture(camera_idx, backend)
                            
                            # æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æˆåŠŸæ‰“å¼€
                            if st.session_state.camera.isOpened():
                                # å°è¯•è·å–ä¸€å¸§æ¥éªŒè¯
                                ret, test_frame = st.session_state.camera.read()
                                if ret:
                                    # è®¾ç½®æ‘„åƒå¤´å‚æ•°
                                    st.session_state.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                                    st.session_state.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                                    
                                    # è·å–å®é™…çš„æ‘„åƒå¤´å‚æ•°
                                    actual_width = st.session_state.camera.get(cv2.CAP_PROP_FRAME_WIDTH)
                                    actual_height = st.session_state.camera.get(cv2.CAP_PROP_FRAME_HEIGHT)
                                    actual_fps = st.session_state.camera.get(cv2.CAP_PROP_FPS)
                                    
                                    camera_opened = True
                                    print(f"æˆåŠŸæ‰“å¼€æ‘„åƒå¤´ï¼Œåˆ†è¾¨ç‡: {actual_width}x{actual_height}, FPS: {actual_fps}")
                                    image_placeholder.info(f"æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ! åˆ†è¾¨ç‡: {int(actual_width)}x{int(actual_height)}")
                                    time.sleep(1)  # ç»™ç”¨æˆ·æ—¶é—´çœ‹åˆ°çŠ¶æ€
                                else:
                                    # æ— æ³•è¯»å–å¸§
                                    print(f"æ‘„åƒå¤´å·²æ‰“å¼€ä½†æ— æ³•è¯»å–å¸§")
                                    st.session_state.camera.release()
                                    st.session_state.camera = None
                        except Exception as e:
                            print(f"æ‰“å¼€æ‘„åƒå¤´æ—¶å‡ºé”™: {str(e)}")
                            if st.session_state.camera is not None:
                                st.session_state.camera.release()
                                st.session_state.camera = None
                        
                        if not camera_opened:
                            error_msg = "æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼Œè¯·æ£€æŸ¥:\n1. æ‘„åƒå¤´è¿æ¥æ˜¯å¦æ­£ç¡®\n2. åº”ç”¨æ˜¯å¦æœ‰æ‘„åƒå¤´è®¿é—®æƒé™\n3. å…¶ä»–ç¨‹åºæ˜¯å¦å ç”¨äº†æ‘„åƒå¤´"
                            print("é”™è¯¯: " + error_msg)
                            image_placeholder.error(error_msg)
                            st.session_state.running = False
                            return
                
                # æ˜¾ç¤ºåŠ è½½ä¿¡æ¯
                image_placeholder.info("æ­£åœ¨åˆå§‹åŒ–æ‘„åƒå¤´...")
                
                # åˆå§‹åŒ–é¢„æµ‹ç»“æœ
                last_prediction = None
                prediction_count = 0
                prediction_history = []
                
                # ä¸»å¾ªç¯ - ä½¿ç”¨whileè€Œéæ— é™å¾ªç¯ï¼Œé¿å…Streamlitå´©æºƒ
                import threading
                import queue
                
                # åˆ›å»ºé˜Ÿåˆ—ç”¨äºä¼ é€’å¸§å’Œç»“æœ
                frame_queue = queue.Queue(maxsize=1)
                result_queue = queue.Queue(maxsize=1)
                
                def process_frames():
                    """åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¤„ç†è§†é¢‘å¸§"""
                    # ç¡®ä¿åœ¨è®¿é—®å‰æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨
                    while True:
                        if 'running' not in st.session_state or not st.session_state.running:
                            break
                        if frame_queue.empty():
                            time.sleep(0.01)
                            continue
                        
                        try:
                            frame = frame_queue.get(timeout=0.1)
                            
                            # æ£€æµ‹æ‰‹éƒ¨å…³é”®ç‚¹
                            landmarks, annotated_frame = st.session_state.detector.detect(frame)
                            
                            prediction = None
                            confidence = 0.0
                            
                            if landmarks is not None:
                                # æå–ç‰¹å¾
                                features = st.session_state.detector.extract_features(landmarks)
                                
                                if features is not None:
                                    # é¢„æµ‹æ‰‹åŠ¿
                                    pred, conf = st.session_state.classifier.predict(features)
                                    prediction, confidence = smooth_prediction(pred)
                            
                            # åœ¨å›¾åƒä¸Šç»˜åˆ¶ç»“æœ
                            if prediction:
                                cv2.putText(annotated_frame, f"æ‰‹åŠ¿: {prediction}",
                                          (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
                                cv2.putText(annotated_frame, f"ç½®ä¿¡åº¦: {confidence:.1%}",
                                          (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                            else:
                                cv2.putText(annotated_frame, "æœªæ£€æµ‹åˆ°æ‰‹",
                                          (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                                cv2.putText(annotated_frame, "è¯·å°†æ‰‹æ”¾åœ¨æ‘„åƒå¤´å‰",
                                          (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                            
                            # è½¬æ¢ä¸ºRGB
                            annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                            
                            # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
                            if not result_queue.full():
                                result_queue.put((annotated_frame_rgb, prediction, confidence), timeout=0.1)
                        except Exception as e:
                            print(f"å¤„ç†å¸§æ—¶å‡ºé”™: {str(e)}")
                
                # å¯åŠ¨å¤„ç†çº¿ç¨‹
                processing_thread = threading.Thread(target=process_frames)
                processing_thread.daemon = True
                processing_thread.start()
                
                # ä¸»æ˜¾ç¤ºå¾ªç¯
                try:
                    frame_count = 0
                    error_count = 0
                    
                    while st.session_state.running:
                        # è¯»å–æ‘„åƒå¤´å¸§
                        try:
                            ret, frame = st.session_state.camera.read()
                            frame_count += 1
                            
                            if not ret:
                                error_count += 1
                                print(f"æ— æ³•è¯»å–æ‘„åƒå¤´å¸§ï¼Œè®¡æ•°: {frame_count}, é”™è¯¯æ•°: {error_count}")
                                
                                # å¦‚æœè¿ç»­å¤šæ¬¡è¯»å–å¤±è´¥ï¼Œè®¤ä¸ºæ‘„åƒå¤´å‡ºç°é—®é¢˜
                                if error_count >= 5:
                                    image_placeholder.error("æ‘„åƒå¤´è¯»å–æŒç»­å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ‘„åƒå¤´è¿æ¥")
                                    break
                                
                                # çŸ­æš‚ç­‰å¾…åé‡è¯•
                                time.sleep(0.1)
                                continue
                            else:
                                # é‡ç½®é”™è¯¯è®¡æ•°
                                error_count = 0
                                
                                # å¦‚æœæ˜¯ç¬¬1å¸§ï¼Œè®°å½•æˆåŠŸä¿¡æ¯
                                if frame_count == 1:
                                    print(f"æˆåŠŸè¯»å–ç¬¬ä¸€å¸§ï¼Œåˆ†è¾¨ç‡: {frame.shape[1]}x{frame.shape[0]}")
                        except Exception as e:
                            error_count += 1
                            print(f"è¯»å–æ‘„åƒå¤´å¸§æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                            if error_count >= 3:
                                image_placeholder.error(f"æ‘„åƒå¤´è¯»å–å¼‚å¸¸: {str(e)}")
                                break
                            time.sleep(0.1)
                            continue
                        
                        # æ°´å¹³ç¿»è½¬ï¼ˆé•œåƒæ•ˆæœï¼‰
                        frame = cv2.flip(frame, 1)
                        
                        # å°†å¸§æ”¾å…¥é˜Ÿåˆ—
                        if not frame_queue.full():
                            try:
                                frame_queue.put(frame, timeout=0.1)
                            except queue.Full:
                                print("å¸§é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä¸€å¸§")
                        else:
                            print("å¸§é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä¸€å¸§")
                        
                        # ä»ç»“æœé˜Ÿåˆ—è·å–å¤„ç†åçš„å›¾åƒ
                        if not result_queue.empty():
                            try:
                                annotated_frame_rgb, prediction, confidence = result_queue.get(timeout=0.1)
                                
                                # æ›´æ–°å›¾åƒ
                                image_placeholder.image(annotated_frame_rgb, channels="RGB")
                            except Exception as e:
                                # å¤„ç†å¯èƒ½çš„é˜Ÿåˆ—å¼‚å¸¸
                                print(f"ä»ç»“æœé˜Ÿåˆ—è·å–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                                prediction = None
                                confidence = 0
                                
                                # æ›´æ–°é¢„æµ‹å†å²
                                if prediction:
                                    prediction_history.append(prediction)
                                    if len(prediction_history) > 10:
                                        prediction_history.pop(0)
                                    
                                    # ç®€å•çš„é¢„æµ‹å¹³æ»‘ - å–æœ€è¿‘å‡ºç°æœ€å¤šçš„é¢„æµ‹
                                    from collections import Counter
                                    if len(prediction_history) >= 3:
                                        counter = Counter(prediction_history[-3:])
                                        most_common = counter.most_common(1)[0]
                                        if most_common[1] >= 2:  # å¦‚æœè‡³å°‘å‡ºç°2æ¬¡
                                            last_prediction = most_common[0]
                                            
                                            # æ›´æ–°æ£€æµ‹å†å²
                                            if last_prediction not in st.session_state.detection_history[-5:]:
                                                st.session_state.detection_history.append(last_prediction)
                                                if len(st.session_state.detection_history) > 20:
                                                    st.session_state.detection_history = st.session_state.detection_history[-20:]
                        
                        # æ·»åŠ çŸ­æš‚å»¶è¿Ÿä»¥é¿å…CPUå ç”¨è¿‡é«˜
                        time.sleep(0.05)
                        
                except Exception as e:
                    st.error(f"è§†é¢‘å¤„ç†å‡ºé”™: {str(e)}")
                finally:
                    # æ¸…ç†èµ„æº
                    st.session_state.running = False
                    if st.session_state.camera is not None:
                        st.session_state.camera.release()
                        st.session_state.camera = None
            except Exception as e:
                st.error(f"å¯åŠ¨æ‘„åƒå¤´å¤±è´¥: {str(e)}")
                st.session_state.running = False
                if st.session_state.camera is not None:
                    st.session_state.camera.release()
                    st.session_state.camera = None
        else:
            # æ˜¾ç¤ºé»˜è®¤æç¤ºå›¾åƒ
            default_image = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(default_image, "ç‚¹å‡»'å¼€å§‹è¯†åˆ«'å¯åŠ¨æ‘„åƒå¤´",
                        (50, 240), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 165, 255), 3)
            default_image_rgb = cv2.cvtColor(default_image, cv2.COLOR_BGR2RGB)
            image_placeholder.image(default_image_rgb, channels="RGB")
    
    with col2:
        st.subheader("ğŸ“Š è¯†åˆ«ç»“æœ")
        
        # æ˜¾ç¤ºæœ€æ–°é¢„æµ‹ç»“æœ
        if 'prediction_history' in locals() and last_prediction:
            st.markdown(f"""
            <div class="prediction-box">
                <div class="prediction-text">{last_prediction}</div>
                <div class="confidence-text">ç½®ä¿¡åº¦: {confidence:.1%}</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="prediction-box">
                <div class="prediction-text">--</div>
                <div class="confidence-text">ç­‰å¾…è¯†åˆ«...</div>
            </div>
            """, unsafe_allow_html=True)
        
        # æ˜¾ç¤ºè¯†åˆ«å†å²
        st.subheader("ğŸ“ æœ€è¿‘è¯†åˆ«å†å²")
        if st.session_state.detection_history:
            for i, pred in enumerate(reversed(st.session_state.detection_history[-10:]), 1):
                st.write(f"{i}. {pred}")
        else:
            st.info("æš‚æ— è¯†åˆ«è®°å½•")
        
        # æ¸…ç©ºå†å²æŒ‰é’®
        if st.button("ğŸ§¹ æ¸…ç©ºå†å²", key="clear_history"):
            st.session_state.detection_history = []
            st.experimental_rerun()

def show_data_collection_page():
    """æ˜¾ç¤ºæ•°æ®æ”¶é›†é¡µé¢"""
    st.header("ğŸ“š æ•°æ®æ”¶é›†å·¥å…·")
    st.info("ğŸ’¡ æ•°æ®æ”¶é›†åŠŸèƒ½éœ€è¦åœ¨æœ¬åœ°è¿è¡Œã€‚è¯·ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼š`python data_collector.py`")
    
    st.markdown("""
    ### ä½¿ç”¨æ­¥éª¤ï¼š
    1. è¿è¡Œæ•°æ®æ”¶é›†å·¥å…·ï¼š`python data_collector.py`
    2. æŒ‰ç…§æç¤ºæ”¶é›†æ¯ä¸ªæ‰‹åŠ¿çš„æ ·æœ¬
    3. æ¯ä¸ªæ‰‹åŠ¿å»ºè®®æ”¶é›†100ä¸ªæ ·æœ¬
    4. æ”¶é›†å®Œæˆåè¿è¡Œè®­ç»ƒè„šæœ¬ï¼š`python train_model.py`
    """)

def show_training_page():
    """æ˜¾ç¤ºæ¨¡å‹è®­ç»ƒé¡µé¢"""
    st.header("ğŸ¤– æ¨¡å‹è®­ç»ƒ")
    st.info("ğŸ’¡ æ¨¡å‹è®­ç»ƒåŠŸèƒ½éœ€è¦åœ¨æœ¬åœ°è¿è¡Œã€‚è¯·ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼š`python train_model.py`")
    
    st.markdown("""
    ### è®­ç»ƒæ­¥éª¤ï¼š
    1. ç¡®ä¿å·²æ”¶é›†è®­ç»ƒæ•°æ®ï¼ˆè¿è¡Œ `data_collector.py`ï¼‰
    2. è¿è¡Œè®­ç»ƒè„šæœ¬ï¼š`python train_model.py`
    3. ç­‰å¾…è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å°†ä¿å­˜ä¸º `gesture_model.pkl`
    
    ### è®­ç»ƒå‚æ•°ï¼š
    - ç®—æ³•ï¼šéšæœºæ£®æ—åˆ†ç±»å™¨
    - æ ‘çš„æ•°é‡ï¼š300
    - æœ€å¤§æ·±åº¦ï¼š20
    - æµ‹è¯•é›†æ¯”ä¾‹ï¼š20%
    """)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    st.subheader("ğŸ“ æ•°æ®æ–‡ä»¶æ£€æŸ¥")
    data_dir = "training_data"
    
    col1, col2 = st.columns(2)
    with col1:
        features_exists = os.path.exists(os.path.join(data_dir, "features.npy"))
        if features_exists:
            st.success("âœ… features.npy å­˜åœ¨")
        else:
            st.error("âŒ features.npy ä¸å­˜åœ¨")
    
    with col2:
        labels_exists = os.path.exists(os.path.join(data_dir, "labels.npy"))
        if labels_exists:
            st.success("âœ… labels.npy å­˜åœ¨")
        else:
            st.error("âŒ labels.npy ä¸å­˜åœ¨")
    
    model_exists = os.path.exists("gesture_model.pkl")
    if model_exists:
        st.success("âœ… å·²è®­ç»ƒæ¨¡å‹å­˜åœ¨")
    else:
        st.warning("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")

def show_instructions_page():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜é¡µé¢"""
    st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
    
    st.markdown("""
    ## ğŸ¯ å¦‚ä½•ä½¿ç”¨
    
    ### ç¬¬ä¸€æ­¥ï¼šå…è®¸æ‘„åƒå¤´è®¿é—®
    1. ç‚¹å‡»"å®æ—¶è¯†åˆ«"é¡µé¢
    2. æµè§ˆå™¨ä¼šè¯·æ±‚æ‘„åƒå¤´æƒé™ï¼Œè¯·ç‚¹å‡»"å…è®¸"
    3. ç¡®ä¿æ‘„åƒå¤´æ­£å¸¸å·¥ä½œ
    
    ### ç¬¬äºŒæ­¥ï¼šå¼€å§‹è¯†åˆ«
    1. å°†æ‰‹æ”¾åœ¨æ‘„åƒå¤´å‰
    2. åšå‡ºæ‰‹è¯­å­—æ¯æ‰‹åŠ¿
    3. ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«å¹¶æ˜¾ç¤ºç»“æœ
    
    ## ğŸ“‹ æ”¯æŒçš„æ‰‹åŠ¿
    
    è½¯ä»¶æ”¯æŒè¯†åˆ«ä»¥ä¸‹30ä¸ªæ‰‹è¯­å­—æ¯ï¼š
    - **A-Z**ï¼ˆ26ä¸ªè‹±æ–‡å­—æ¯ï¼‰
    - **ZH, CH, SH, NG**ï¼ˆ4ä¸ªæ±‰è¯­æ‹¼éŸ³å£°æ¯ï¼‰
    
    ## ğŸ’¡ ä½¿ç”¨æç¤º
    
    1. âœ… **å…‰ç…§æ¡ä»¶**ï¼šåœ¨æ˜äº®ã€å‡åŒ€çš„å…‰ç…§ä¸‹ä½¿ç”¨æ•ˆæœæœ€ä½³
    2. âœ… **æ‰‹åŠ¿æ¸…æ™°**ï¼šä¿æŒæ‰‹åŠ¿æ¸…æ™°ï¼Œæ‰‹æŒ‡å®Œå…¨å±•å¼€æˆ–å¼¯æ›²
    3. âœ… **ä¿æŒç¨³å®š**ï¼šæ¯ä¸ªæ‰‹åŠ¿ä¿æŒ2-3ç§’ï¼Œé¿å…å¿«é€Ÿç§»åŠ¨
    4. âœ… **å®Œæ•´æ˜¾ç¤º**ï¼šç¡®ä¿æ‰‹éƒ¨å®Œå…¨åœ¨æ‘„åƒå¤´è§†é‡å†…
    5. âœ… **èƒŒæ™¯ç®€æ´**ï¼šä½¿ç”¨ç®€æ´çš„èƒŒæ™¯ï¼Œé¿å…å¹²æ‰°
    
    ## ğŸ”§ æ•…éšœæ’é™¤
    
    ### æ‘„åƒå¤´æ— æ³•è®¿é—®
    - âœ… æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦å·²æˆæƒæ‘„åƒå¤´æƒé™
    - âœ… ç¡®ä¿æ²¡æœ‰å…¶ä»–ç¨‹åºå ç”¨æ‘„åƒå¤´
    - âœ… å°è¯•åˆ·æ–°é¡µé¢æˆ–ä½¿ç”¨Chrome/Firefoxæµè§ˆå™¨
    - âœ… æ£€æŸ¥ç³»ç»Ÿæ‘„åƒå¤´è®¾ç½®
    
    ### è¯†åˆ«ä¸å‡†ç¡®
    - âœ… ç¡®ä¿å…‰ç…§å……è¶³ä¸”å‡åŒ€
    - âœ… ä¿æŒæ‰‹åŠ¿æ¸…æ™°ç¨³å®š
    - âœ… ç¡®ä¿æ‰‹éƒ¨å®Œå…¨åœ¨ç”»é¢ä¸­
    - âœ… å°è¯•è°ƒæ•´æ‰‹ä¸æ‘„åƒå¤´çš„è·ç¦»ï¼ˆçº¦30-50cmï¼‰
    
    ### æ²¡æœ‰è¯†åˆ«ç»“æœ
    - âœ… æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°æ‰‹éƒ¨ï¼ˆæŸ¥çœ‹ç”»é¢ä¸­çš„ç»¿è‰²çº¿æ¡ï¼‰
    - âœ… ç¡®ä¿æ‰‹åŠ¿æ­£ç¡®
    - âœ… å°è¯•é‡æ–°è°ƒæ•´æ‰‹çš„ä½ç½®
    
    ## ğŸŒ å…³äºæ­¤åº”ç”¨
    
    è¿™æ˜¯ä¸€ä¸ªåŸºäºMediaPipeå’Œæœºå™¨å­¦ä¹ çš„æ‰‹è¯­è¯†åˆ«ç³»ç»Ÿã€‚
    
    - **æŠ€æœ¯æ ˆ**ï¼šOpenCV, MediaPipe, scikit-learn, Streamlit
    - **è¯†åˆ«ç®—æ³•**ï¼šéšæœºæ£®æ—åˆ†ç±»å™¨
    - **æ‰‹éƒ¨æ£€æµ‹**ï¼šMediaPipe Hands
    
    ## ğŸ“ è·å–å¸®åŠ©
    
    å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š
    1. æŸ¥çœ‹æœ¬é¡µé¢çš„æ•…éšœæ’é™¤éƒ¨åˆ†
    2. æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
    3. å°è¯•åˆ·æ–°é¡µé¢é‡æ–°åŠ è½½
    """)
    
    # æ·»åŠ éƒ¨ç½²ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯äº‘ç«¯éƒ¨ç½²ï¼‰
    st.markdown("---")
    st.info("""
    ğŸ’¡ **æç¤º**ï¼šæ­¤åº”ç”¨å·²éƒ¨ç½²åˆ°äº‘ç«¯ï¼Œä»»ä½•äººéƒ½å¯ä»¥é€šè¿‡é“¾æ¥è®¿é—®ä½¿ç”¨ã€‚
    æ— éœ€å®‰è£…ä»»ä½•è½¯ä»¶ï¼Œåªéœ€è¦æµè§ˆå™¨å’Œæ‘„åƒå¤´å³å¯ï¼
    """)

if __name__ == "__main__":
    main()

